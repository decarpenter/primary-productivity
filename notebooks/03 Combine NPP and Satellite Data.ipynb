{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417ae990-41d3-45c1-bc0f-ee459e43b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pydeck as pdk\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\".*A worker stopped while some jobs were given to the executor.*\",\n",
    "    category=UserWarning\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bbe092-575d-4774-a8a4-4584376bf2ab",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7129e268-1652-46fd-b15f-636f614b5743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Integrated NPP Data from CalCOFI Bottle Survey\n",
    "npp = pd.read_csv('../data/CalCOFI_Integrated_NPP.csv', index_col=0)\n",
    "npp = npp[['Date', 'Latitude', 'Longitude', 'Integrated_NPP']]\n",
    "npp['Date'] = pd.to_datetime(npp['Date'])\n",
    "npp = npp.sort_values(by='Date').reset_index(drop=True)\n",
    "npp = npp[npp.Date >= '1997-09-04'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e3c21c-9186-4044-9507-291b381e0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load satellite data (CHL, PAR, SST)\n",
    "print('loading data...')\n",
    "chl_ds   = xr.open_dataset('/Users/deliacarpenter/Desktop/Research/Primary Productivity CalCOFI/cmems satellite data original grid/cmems_obs-oc_glo_bgc-plankton_my_l3-multi-4km_P1D_CHL_126.98W-109.02W_22.02N-40.98N_1997-09-04-2020-01-25.nc')\n",
    "par_ds   = xr.open_dataset('/Users/deliacarpenter/Desktop/Research/Primary Productivity CalCOFI/reindexed satellite data/reindexed_PAR_globcolour_4km_daily_merged_L3m.nc')\n",
    "sst_ds   = xr.open_dataset('/Users/deliacarpenter/Desktop/Research/Primary Productivity CalCOFI/reindexed satellite data/reindexed_cmems_obs-sst_glo_phy_my_l3s_P1D-m_multi-vars_126.95W-109.05W_22.05N-40.95N_1997-09-04-2020-01-25.nc')\n",
    "kd490_ds = xr.open_dataset('/Users/deliacarpenter/Desktop/Research/Primary Productivity CalCOFI/reindexed satellite data/reindexed_cmems_obs-oc_glo_bgc-transp_my_l3-multi-4km_P1D_KD490_126.98W-109.02W_22.02N-40.98N_1997-09-04-2020-01-25.nc')\n",
    "C_ds     = xr.open_dataset('/Users/deliacarpenter/Desktop/Research/Primary Productivity CalCOFI/reindexed satellite data/reindexed_cmems_obs-oc_glo_bgc-optics_my_l3-multi-4km_P1D_BBP_and_phyto_C_126.98W-109.02W_22.02N-40.98N_1997-09-04-2020-01-25.nc')\n",
    "mld_ds   = xr.open_dataset('/Users/deliacarpenter/Desktop/Research/Primary Productivity CalCOFI/reindexed satellite data/reindexed_cmems_mod_glo_phy_my_0.083deg_P1D-m_mlotst_127.00W-109.08W_22.08N-41.00N_1997-09-04-2020-01-25.nc')\n",
    "chlc_ds  = xr.open_dataset('/Users/deliacarpenter/Desktop/Research/Primary Productivity CalCOFI/reindexed satellite data/reindexed_cmems_obs-oc_glo_bgc-optics_my_l3-multi-4km_P1D_CHLC_ratio_126.98W-109.02W_22.02N-40.98N_1997-09-04-2020-01-25.nc')\n",
    "cdm_ds   = xr.open_dataset('/Users/deliacarpenter/Desktop/Research/Primary Productivity CalCOFI/reindexed satellite data/reindexed_cmems_obs-oc_glo_bgc-optics_my_l3-multi-4km_P1D_CDM_126.98W-109.02W_22.02N-40.98N_1997-09-04-2020-01-25.nc')\n",
    "spm_ds   = xr.open_dataset('/Users/deliacarpenter/Desktop/Research/Primary Productivity CalCOFI/reindexed satellite data/reindexed_cmems_obs-oc_glo_bgc-transp_my_l3-multi-4km_P1D_SPM_126.98W-109.02W_22.02N-40.98N_1997-09-04-2020-01-25.nc')\n",
    "phyt_ds  = xr.open_dataset('/Users/deliacarpenter/Desktop/Research/Primary Productivity CalCOFI/reindexed satellite data/reindexed_cmems_obs-oc_glo_bgc-plankton_my_l3-multi-4km_P1D_multi-vars_126.98W-109.02W_22.02N-40.98N_1997-09-04-2020-01-25.nc')\n",
    "wind_ds  = xr.open_dataset('/Users/deliacarpenter/Desktop/Research/Primary Productivity CalCOFI/reindexed satellite data/reindexed_wind_ds.nc')\n",
    "no3_ds   = xr.open_dataset('/Users/deliacarpenter/Desktop/Research/Primary Productivity CalCOFI/reindexed satellite data/reindexed_cmems_mod_glo_bgc_my_0.25deg_P1D-m_no3_127.00W-109.25W_22.25N-41.00N_0.51m_1997-09-04-2020-01-25.nc')\n",
    "rrs_ds   = xr.open_dataset('/Users/deliacarpenter/Desktop/Research/Primary Productivity CalCOFI/reindexed satellite data/reindexed_cmems_obs-oc_glo_bgc-reflectance_my_l3-multi-4km_P1D_multi-vars_126.98W-109.02W_22.02N-40.98N_1997-09-04-2020-01-25.nc')\n",
    "zsd_ds   = xr.open_dataset('/Users/deliacarpenter/Desktop/Research/Primary Productivity CalCOFI/reindexed satellite data/reindexed_cmems_obs-oc_glo_bgc-transp_my_l3-multi-4km_P1D_ZSD_126.98W-109.02W_22.02N-40.98N_1997-09-04-2020-01-25.nc')\n",
    "\n",
    "# Make sure everything is an xarray.Dataset (not DataArray)\n",
    "datasets_to_merge = [\n",
    "    chl_ds,\n",
    "    par_ds,\n",
    "    sst_ds,\n",
    "    kd490_ds,\n",
    "    C_ds,\n",
    "    mld_ds,\n",
    "    chlc_ds,\n",
    "    cdm_ds,\n",
    "    spm_ds,\n",
    "    phyt_ds,\n",
    "    wind_ds,\n",
    "    no3_ds,\n",
    "    rrs_ds,\n",
    "    zsd_ds,\n",
    "]\n",
    "\n",
    "# Align datasets\n",
    "print(\"aligning...\")\n",
    "aligned = xr.align(*datasets_to_merge, join=\"inner\")  # or try \"inner\" for safety\n",
    "\n",
    "# Merge all datasets\n",
    "print('merging data...')\n",
    "satellite_ds = xr.merge(datasets_to_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00faf18d-bffb-4a9c-97bc-c1e7fdc1c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add MESD to satellite_ds\n",
    "\n",
    "# Define representative diameters in microns for each group\n",
    "d_pico = 0.7\n",
    "d_nano = 5.0\n",
    "d_micro = 50.0\n",
    "\n",
    "# Pull the variables from the dataset\n",
    "PICO = satellite_ds['PICO']\n",
    "NANO = satellite_ds['NANO']\n",
    "MICRO = satellite_ds['MICRO']\n",
    "\n",
    "# Compute biomass-weighted mean cell size (in microns)\n",
    "numerator = (PICO * d_pico) + (NANO * d_nano) + (MICRO * d_micro)\n",
    "denominator = PICO + NANO + MICRO\n",
    "\n",
    "# Avoid divide-by-zero\n",
    "MESD = xr.where(denominator > 0, numerator / denominator, np.nan)\n",
    "\n",
    "# Assign to dataset\n",
    "satellite_ds['MESD'] = MESD\n",
    "satellite_ds['MESD'].attrs['units'] = 'µm'\n",
    "satellite_ds['MESD'].attrs['long_name'] = 'Mean Estimated Spherical Diameter (biomass-weighted)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5038ac-6813-4c3a-a14a-9d6f9e337cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize one day of satellite data\n",
    "\n",
    "# Select one day\n",
    "date = '2015-10-30'\n",
    "ds_day = satellite_ds.sel(time=date)\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(16, 12))\n",
    "axs = axs.ravel()\n",
    "\n",
    "vars_to_plot = ['CHL', 'PAR', 'SST', \n",
    "                'KD490', 'MLD', 'CDM', \n",
    "                'SPM', 'wind_stress_curl', 'MESD']\n",
    "\n",
    "for i, var in enumerate(vars_to_plot):\n",
    "    data = ds_day[var]\n",
    "    values = data.values.flatten()\n",
    "    values = values[~np.isnan(values)]  # remove NaNs\n",
    "\n",
    "    # Compute 10th and 90th percentiles\n",
    "    vmin = np.percentile(values, 10)\n",
    "    vmax = np.percentile(values, 90)\n",
    "\n",
    "    data.plot(ax=axs[i], cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "    axs[i].set_title(var)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30757a34-083b-4ebb-8bc2-21738a1699d1",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85966601-c637-4616-a0fa-093b7ec3a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_grid_window(res_km, target_area_km2=729, valid_fraction=1/3):\n",
    "    \"\"\"\n",
    "    Calculate the size of an n x n satellite pixel grid that best approximates a target spatial area, \n",
    "    and determine the minimum number of valid pixels required within that grid based on a valid fraction.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the ideal grid size (in pixels) to match the target spatial area\n",
    "    ideal_grid_size = math.sqrt(target_area_km2 / (res_km ** 2))\n",
    "    \n",
    "    # Round ideal size to nearest integer to get base grid size\n",
    "    base_grid_size = round(ideal_grid_size)\n",
    "    \n",
    "    # Find nearest odd integer grid sizes: one just below or equal, and one just above\n",
    "    odd_floor = base_grid_size if base_grid_size % 2 == 1 else base_grid_size - 1\n",
    "    odd_ceil = odd_floor + 2  # Next odd number above odd_floor\n",
    "    \n",
    "    # Compute the actual spatial areas these two grid sizes represent\n",
    "    area_floor = (odd_floor * res_km) ** 2\n",
    "    area_ceil = (odd_ceil * res_km) ** 2\n",
    "    \n",
    "    # Choose the odd grid size with the area closest to the target area\n",
    "    if abs(area_floor - target_area_km2) <= abs(area_ceil - target_area_km2):\n",
    "        n = odd_floor\n",
    "    else:\n",
    "        n = odd_ceil\n",
    "    \n",
    "    # Calculate total number of pixels in the grid window\n",
    "    total_pixels = n ** 2\n",
    "    \n",
    "    # Calculate the minimum number of valid pixels required, rounding to nearest integer\n",
    "    min_valid_pixels = int(valid_fraction * total_pixels + 0.5)\n",
    "    \n",
    "    return n, min_valid_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b21ccdc-d031-4d04-9910-b851e194c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Integrated NPP Data from CalCOFI Bottle Survey\n",
    "npp = pd.read_csv('../data/CalCOFI_Integrated_NPP.csv', index_col=0)\n",
    "npp = npp[['Date', 'Latitude', 'Longitude', 'Integrated_NPP']]\n",
    "npp['Date'] = pd.to_datetime(npp['Date'])\n",
    "npp = npp.sort_values(by='Date').reset_index(drop=True)\n",
    "npp = npp[npp.Date >= '1997-09-04'].reset_index(drop=True)\n",
    "\n",
    "# Precompute nearest lat/lon indices\n",
    "ds_lats = satellite_ds.latitude.values\n",
    "ds_lons = satellite_ds.longitude.values\n",
    "\n",
    "npp['ilat'] = np.abs(ds_lats[:, None] - npp['Latitude'].values).argmin(axis=0)\n",
    "npp['ilon'] = np.abs(ds_lons[:, None] - npp['Longitude'].values).argmin(axis=0)\n",
    "\n",
    "# Clip to valid range\n",
    "npp['ilat'] = np.clip(npp['ilat'], 0, len(ds_lats) - 1)\n",
    "npp['ilon'] = np.clip(npp['ilon'], 0, len(ds_lons) - 1)\n",
    "\n",
    "# Calculate grid size and min_valid_pixels for satellite data\n",
    "res_km = 4\n",
    "grid_size, min_valid_pixels = calculate_grid_window(res_km)\n",
    "\n",
    "# Precompute spatial window slices\n",
    "half = grid_size // 2\n",
    "npp['lat0'] = np.clip(npp['ilat'] - half, 0, len(ds_lats) - 1)\n",
    "npp['lat1'] = np.clip(npp['ilat'] + half + 1, 0, len(ds_lats))\n",
    "npp['lon0'] = np.clip(npp['ilon'] - half, 0, len(ds_lons) - 1)\n",
    "npp['lon1'] = np.clip(npp['ilon'] + half + 1, 0, len(ds_lons))\n",
    "\n",
    "# Get nearest time index for each NPP observation\n",
    "ds_times = satellite_ds.time.values.astype('datetime64[D]')\n",
    "npp_times = npp['Date'].values.astype('datetime64[D]')\n",
    "\n",
    "npp['itime'] = np.searchsorted(ds_times, npp_times)\n",
    "npp['itime'] = np.clip(npp['itime'], 0, len(ds_times) - 1)\n",
    "\n",
    "display(npp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541fefcd-4bcd-459d-8254-6260fd92c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_satellite_features(i, var, min_valid_pixels, max_day_offset=3):\n",
    "    ''' Return an (n x n) spatial grid for variable 'var' for lags [-14, -7, 0, 7, 14], computing the following:\n",
    "        - Instantaneous satellite grid values for lags [-14, -7, 0, 7, 14]\n",
    "        - Mean over time windows [past two weeks, past week, this week, this and next week, this and next two weeks]\n",
    "        - Variance over different time windows [past two weeks, past week, this week, this and next week, this and next two weeks]\n",
    "    '''\n",
    "    \n",
    "    global satellite_ds # access without passing it\n",
    "    \n",
    "    # Time indices for instantaneous values (±3-day window around the target lag)\n",
    "    LAG_WINDOWS = {\n",
    "        -14: (-17, -11),\n",
    "        -7:  (-10, -4),\n",
    "        0:  (-3,  3),\n",
    "        7:  ( 4, 10),\n",
    "        14:  (11, 17),\n",
    "    }\n",
    "    # Time indices for moving windows (moving-window statistics over all days you want to include)\n",
    "    WINDOW_INDICES = {\n",
    "        -14: (-17, 3),\n",
    "        -7:  (-10, 3),\n",
    "        0:  (-3, 3),\n",
    "        7:  (-3, 10),\n",
    "        14:  (-3, 17)\n",
    "    }\n",
    "    row = npp.loc[i]\n",
    "    lat0, lat1, lon0, lon1, itime = row.lat0, row.lat1, row.lon0, row.lon1, row.itime\n",
    "    \n",
    "    # --- Subset full temporal cube for this NPP observation ---\n",
    "    t0 = max(itime - 17, 0)\n",
    "    t1 = min(itime + 18, satellite_ds.sizes['time'])\n",
    "    da = satellite_ds[var].isel(\n",
    "        time=slice(t0, t1),\n",
    "        latitude=slice(lat0, lat1),\n",
    "        longitude=slice(lon0, lon1)\n",
    "    )\n",
    "\n",
    "    # Map absolute time to relative index in da\n",
    "    rel_itime = itime - t0\n",
    "\n",
    "    lags = [-14, -7, 0, 7, 14]\n",
    "    moving_window_stats = ['value', 'mean', 'variance']\n",
    "\n",
    "    results = {}\n",
    "    for stat in moving_window_stats:\n",
    "        for lag in lags:\n",
    "            # Find satellite values for nearest day\n",
    "            if stat == 'value':\n",
    "                t0_lag_rel, t1_lag_rel = LAG_WINDOWS[lag]\n",
    "                found = False\n",
    "                for offset in range(max_day_offset + 1):\n",
    "                    for direction in [-1,1] if offset > 0 else[0]:    # do offset 0 first, then ±1, ±2...\n",
    "                        t_idx = rel_itime + lag + direction * offset\n",
    "                        sat_day = da.isel(time=t_idx)\n",
    "                        if np.isfinite(sat_day).sum() >= min_valid_pixels:\n",
    "                            results[f'{var}_value_{lag}'] = sat_day\n",
    "                            found = True\n",
    "                            break\n",
    "                    if found:\n",
    "                        break\n",
    "                if not found:\n",
    "                    results[f'{var}_value_{lag}'] = np.full(\n",
    "                    (da.sizes['latitude'], da.sizes['longitude']),\n",
    "                    np.nan,\n",
    "                    dtype=np.float32\n",
    "                    )\n",
    "    \n",
    "            # Take moving_window_stat over specified window\n",
    "            elif stat in ['mean', 'variance']:\n",
    "                t0_rel_idx, t1_rel_idx = WINDOW_INDICES[lag]\n",
    "                t0_rel_idx = rel_itime + t0_rel_idx\n",
    "                t1_rel_idx = rel_itime + t1_rel_idx\n",
    "                sat_cube = da.isel(time=slice(t0_rel_idx, t1_rel_idx+1))\n",
    "    \n",
    "                if stat == 'mean':\n",
    "                    grid = sat_cube.mean(axis=0) # average over time only\n",
    "                elif stat == 'variance':\n",
    "                    grid = sat_cube.var(axis=0)  # variance over time only\n",
    "    \n",
    "                results[f'{var}_{stat}_{lag}'] = grid\n",
    "    \n",
    "    return results\n",
    "\n",
    "i = 1000\n",
    "var = 'MESD'\n",
    "\n",
    "features = extract_satellite_features(i, var, min_valid_pixels, max_day_offset=3)\n",
    "for key in features.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df12d8-e321-4e19-b065-08ebeabb4d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize features of one variable for one NPP observation\n",
    "\n",
    "lags = [-14, -7, 0, 7, 14]\n",
    "stats = ['value', 'mean', 'variance']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(20, 12), sharex=False, sharey=False)\n",
    "fig.suptitle(f'{var} Features for CalCOFI Observation {i} ({npp.loc[i, 'Date']}, Lat = {npp.loc[i, 'Latitude']}, Lon = {npp.loc[i, 'Longitude']})')\n",
    "\n",
    "for i, stat in enumerate(stats):\n",
    "    for j, lag in enumerate(lags):\n",
    "        ax = axes[i, j]\n",
    "        key = f'{var}_{stat}_{lag}'\n",
    "        grid = features[key]\n",
    "        \n",
    "        # Convert to numpy array if xarray\n",
    "        if hasattr(grid, 'values'):\n",
    "            grid_data = grid.values\n",
    "            lat = grid.latitude.values\n",
    "            lon = grid.longitude.values\n",
    "        else:\n",
    "            grid_data = grid\n",
    "            lat = np.arange(grid.shape[0])\n",
    "            lon = np.arange(grid.shape[1])\n",
    "        \n",
    "        im = ax.imshow(grid_data, origin='lower', cmap='viridis',\n",
    "                       extent=[lon[0], lon[-1], lat[0], lat[-1]])\n",
    "        ax.set_title(f'{stat} {lag}')\n",
    "        \n",
    "        # Plot NPP observation as red X in center of grid\n",
    "        lat_c = lat[len(lat)//2]\n",
    "        lon_c = lon[len(lon)//2]\n",
    "        ax.plot(lon_c, lat_c, 'rx', markersize=10)\n",
    "        \n",
    "        fig.colorbar(im, ax=ax, orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa51c9c1-1fa4-417d-9a3c-c5246a69b20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_var(var):\n",
    "    results_list = Parallel(n_jobs=-1)(\n",
    "        delayed(extract_satellite_features)(i, var, min_valid_pixels)\n",
    "        for i in tqdm(npp.index)\n",
    "    )\n",
    "\n",
    "    # convert results to xarray.Dataset\n",
    "    data_vars = {}\n",
    "    for stat in ['value', 'mean', 'variance']:\n",
    "        for lag in [-14, -7, 0, 7, 14]:\n",
    "            arr = np.stack([res[f'{var}_{stat}_{lag}'] for res in results_list], axis=0)\n",
    "            data_vars[f'{stat}_{lag}'] = (('npp', 'lat', 'lon'), arr)\n",
    "\n",
    "    ds = xr.Dataset(\n",
    "        data_vars=data_vars,\n",
    "        coords={\n",
    "            'npp': npp.index.values,\n",
    "            'lat': results_list[0]['value_-14'].latitude.values,\n",
    "            'lon': results_list[0]['value_-14'].longitude.values,\n",
    "            'date': npp['Date'].values\n",
    "        }\n",
    "    )\n",
    "\n",
    "    encoding = {varname: {'zlib': True, 'complevel': 4} for varname in ds.data_vars}\n",
    "    ds.to_netcdf(f'satellite_features/{var}.nc', encoding=encoding)\n",
    "\n",
    "# Run for all variables\n",
    "\n",
    "\n",
    "\n",
    "input_vars = ['CHL', 'PAR', 'SST', 'KD490', 'BBP', 'C', 'MLD', 'CHL:C', 'CDM', 'SPM', \n",
    "              'DIATO', 'DINO', 'GREEN', 'HAPTO', 'MICRO', 'NANO', 'PICO', 'PROCHLO', 'PROKAR', \n",
    "              'u10', 'v10', 'wind_stress_curl', 'no3', \n",
    "              'RRS412', 'RRS443', 'RRS490', 'RRS555', 'RRS670', \n",
    "              'ZSD', 'MESD']\n",
    "\n",
    "for var in input_vars:\n",
    "    print(var)\n",
    "    process_var(var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
